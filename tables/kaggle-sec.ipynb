{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T22:45:24.620077Z",
     "iopub.status.busy": "2025-04-12T22:45:24.619817Z",
     "iopub.status.idle": "2025-04-12T22:45:26.228634Z",
     "shell.execute_reply": "2025-04-12T22:45:26.227813Z",
     "shell.execute_reply.started": "2025-04-12T22:45:24.620055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import numpy as np # linear algebra\n",
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Define the directory containing your CSV files\n",
    "# data_dir = '/kaggle/input/sec-cameco/' if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else '../data/tables_google_ms_nvidia/'\n",
    "data_dir = '/kaggle/input/sec-cameco/' if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else '../data/tables_all/'\n",
    "\n",
    "for dirname, _, filenames in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "def print_duckdb_schema(conn: duckdb.DuckDBPyConnection, table_name: str):\n",
    "  \"\"\"Prints the schema of a specified table in a DuckDB database.\n",
    "\n",
    "  Args:\n",
    "    conn: An active DuckDB connection object.\n",
    "    table_name: The name of the table whose schema to print.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    schema_info = conn.execute(f\"PRAGMA table_info('{table_name}')\").fetchall()\n",
    "    if not schema_info:\n",
    "      print(f\"Table '{table_name}' not found.\")\n",
    "      return\n",
    "\n",
    "    print(f\"Schema for table: {table_name}\")\n",
    "    print(\"-\" * (16 + len(table_name)))\n",
    "    print(f\"{'Column ID':<10} {'Name':<20} {'Type':<15} {'NotNull':<8} {'PrimaryKey':<12} {'Default':<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    for column in schema_info:\n",
    "      cid, name, dtype, notnull, pk, default = column\n",
    "      print(f\"{cid:<10} {name:<20} {dtype:<15} {bool(notnull):<8} {bool(pk):<12} {str(default):<20}\")\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "  except duckdb.CatalogException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"Could not retrieve schema for table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:45:29.776181Z",
     "iopub.status.busy": "2025-04-12T22:45:29.775937Z",
     "iopub.status.idle": "2025-04-12T22:45:30.428515Z",
     "shell.execute_reply": "2025-04-12T22:45:30.427855Z",
     "shell.execute_reply.started": "2025-04-12T22:45:29.776159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sec_pk = {'sub': 'adsh', 'tag': 'tag, version', 'ren': 'adsh, report', 'pre': 'adsh, report, line', 'cal': 'adsh, grp, arc', 'dim': 'dimhash', 'company': 'cik'}\n",
    "# sec_date_column =  {'sub': ['changed', 'period', 'filed', 'floatdate'], 'num': ['ddate'], 'txt': ['ddate']} \n",
    "sec_date_column =  {'sub': ['changed', 'period', 'filed', 'floatdate'], 'num': ['ddate'], 'txt': ['ddate']} \n",
    "# Create an in-memory DuckDB connection\n",
    "# con = duckdb.connect(database=':memory:', read_only=False)\n",
    "con = duckdb.connect(database='../kaggle.db')\n",
    "\n",
    "# List all files in the specified directory\n",
    "all_files = os.listdir(data_dir)\n",
    "\n",
    "# Filter for CSV files (you might need to adjust the extension if your files are different)\n",
    "csv_files = [f for f in all_files if f.endswith('.csv')]\n",
    "\n",
    "# Iterate through the CSV files and load them into DuckDB tables\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    table_name = os.path.splitext(file_name)[0]  # Use the filename (without extension) as the table name\n",
    "\n",
    "    try:\n",
    "        # Option 1: Use pandas to read the CSV file into a DataFrame\n",
    "        #df = pd.read_csv(file_path)\n",
    "\n",
    "        # Load the DataFrame into a DuckDB table\n",
    "        #con.register(table_name, df)  # Register the DataFrame as a view\n",
    "\n",
    "        # Option 2: Using COPY FROM (Faster for large files)\n",
    "        con.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM read_csv('{file_path}', AUTO_DETECT=TRUE);\"\"\")\n",
    "        if table_name in sec_date_column:\n",
    "            strptimes: str = \"\"\n",
    "            for col in sec_date_column[table_name]:\n",
    "                # strptimes += f\"STRPTIME(CAST({col} AS VARCHAR), '%Y%m%d')::DATE AS {col}, \\n\"\n",
    "                # sql_alter = f\"ALTER TABLE {table_name} ALTER COLUMN {col} TYPE DATE USING STRPTIME(CAST({col} AS VARCHAR), '%Y%m%d')::DATE;\" \n",
    "                # sql_alter = f\"ALTER TABLE {table_name} ALTER COLUMN {col} TYPE DATE USING STRPTIME(CAST(FLOOR({col}) AS VARCHAR), '%Y%m%d')::DATE;\"\n",
    "                sql_alter = f\"ALTER TABLE {table_name} ALTER COLUMN {col} TYPE DATE USING STRPTIME(CAST({col} AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\"\n",
    "                print(sql_alter)\n",
    "                con.execute(sql_alter)\n",
    "            # sql_command = f\"\"\"SELECT *, {strptimes.rstrip(', \\n')} FROM {table_name};\"\"\"\n",
    "\n",
    "\n",
    "        if table_name in sec_pk:\n",
    "            # Add primary key constraint\n",
    "            sql_pk = f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({sec_pk[table_name]});\"\n",
    "            print(sql_pk)\n",
    "            con.execute(sql_pk)\n",
    "\n",
    "\n",
    "        print(f\"Loaded '{file_name}' into DuckDB view '{table_name}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading '{file_name}': {e}\")\n",
    "\n",
    "# Now you can query the data in DuckDB using SQL\n",
    "# For example, to select the first few rows of one of your tables:\n",
    "# table_to_query = csv_files[0].split('.')[0] # Get the name of the first table\n",
    "# result = con.execute(f\"SELECT * FROM {table_to_query} LIMIT 5;\").fetchdf()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:46:11.063245Z",
     "iopub.status.busy": "2025-04-12T22:46:11.063015Z",
     "iopub.status.idle": "2025-04-12T22:46:11.093073Z",
     "shell.execute_reply": "2025-04-12T22:46:11.092411Z",
     "shell.execute_reply.started": "2025-04-12T22:46:11.063227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "query_table = 'sub'\n",
    "result = conn.execute(f\"SELECT * FROM {query_table};\")\n",
    "print(result.fetchdf())\n",
    "\n",
    "print_duckdb_schema(con, query_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7126957,
     "sourceId": 11382185,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
