{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T22:45:24.620077Z",
     "iopub.status.busy": "2025-04-12T22:45:24.619817Z",
     "iopub.status.idle": "2025-04-12T22:45:26.228634Z",
     "shell.execute_reply": "2025-04-12T22:45:26.227813Z",
     "shell.execute_reply.started": "2025-04-12T22:45:24.620055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/tables_1009001/dim.csv\n",
      "../data/tables_1009001/tag.csv\n",
      "../data/tables_1009001/pre.csv\n",
      "../data/tables_1009001/num.csv\n",
      "../data/tables_1009001/ren.csv\n",
      "../data/tables_1009001/sub.csv\n",
      "../data/tables_1009001/cal.csv\n",
      "../data/tables_1009001/txt.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Define the directory containing your CSV files\n",
    "data_dir = '/kaggle/input/sec-cameco/' if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else '../data/tables_1009001/'\n",
    "\n",
    "for dirname, _, filenames in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:45:29.776181Z",
     "iopub.status.busy": "2025-04-12T22:45:29.775937Z",
     "iopub.status.idle": "2025-04-12T22:45:30.428515Z",
     "shell.execute_reply": "2025-04-12T22:45:30.427855Z",
     "shell.execute_reply.started": "2025-04-12T22:45:29.776159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALTER TABLE dim ADD PRIMARY KEY (dimhash);\n",
      "Loaded 'dim.csv' into DuckDB view 'dim'\n",
      "ALTER TABLE tag ADD PRIMARY KEY (tag, version);\n",
      "Loaded 'tag.csv' into DuckDB view 'tag'\n",
      "ALTER TABLE pre ADD PRIMARY KEY (adsh, report, line);\n",
      "Loaded 'pre.csv' into DuckDB view 'pre'\n",
      "Loaded 'num.csv' into DuckDB view 'num'\n",
      "ALTER TABLE ren ADD PRIMARY KEY (adsh, report);\n",
      "Loaded 'ren.csv' into DuckDB view 'ren'\n",
      "SELECT *, STRPTIME(CAST(filed AS VARCHAR), '%Y%m%d')::DATE AS filed, \n",
      "STRPTIME(CAST(floatdate AS VARCHAR), '%Y%m%d')::DATE AS floatdate FROM sub;\n",
      "ALTER TABLE sub ADD PRIMARY KEY (adsh);\n",
      "Loaded 'sub.csv' into DuckDB view 'sub'\n",
      "ALTER TABLE cal ADD PRIMARY KEY (adsh, grp, arc);\n",
      "Loaded 'cal.csv' into DuckDB view 'cal'\n",
      "Loaded 'txt.csv' into DuckDB view 'txt'\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "sec_pk = {'sub': 'adsh', 'tag': 'tag, version', 'ren': 'adsh, report', 'pre': 'adsh, report, line', 'cal': 'adsh, grp, arc', 'dim': 'dimhash'}\n",
    "sec_date_column = {'sub': ['filed', 'floatdate']}\n",
    "\n",
    "# Create an in-memory DuckDB connection\n",
    "# con = duckdb.connect(database=':memory:', read_only=False)\n",
    "con = duckdb.connect(database='../kaggle.db')\n",
    "\n",
    "# List all files in the specified directory\n",
    "all_files = os.listdir(data_dir)\n",
    "\n",
    "# Filter for CSV files (you might need to adjust the extension if your files are different)\n",
    "csv_files = [f for f in all_files if f.endswith('.csv')]\n",
    "\n",
    "# Iterate through the CSV files and load them into DuckDB tables\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    table_name = os.path.splitext(file_name)[0]  # Use the filename (without extension) as the table name\n",
    "\n",
    "    try:\n",
    "        # Option 1: Use pandas to read the CSV file into a DataFrame\n",
    "        #df = pd.read_csv(file_path)\n",
    "\n",
    "        # Load the DataFrame into a DuckDB table\n",
    "        #con.register(table_name, df)  # Register the DataFrame as a view\n",
    "\n",
    "        # Option 2: Using COPY FROM (Faster for large files)\n",
    "        con.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM read_csv('{file_path}', AUTO_DETECT=TRUE);\"\"\")\n",
    "        if table_name in sec_date_column:\n",
    "            strptimes: str = \"\"\n",
    "            for col in sec_date_column[table_name]:\n",
    "                strptimes += f\"STRPTIME(CAST({col} AS VARCHAR), '%Y%m%d')::DATE AS {col}, \\n\"\n",
    "            sql_command = f\"\"\"SELECT *, {strptimes.rstrip(', \\n')} FROM {table_name};\"\"\"\n",
    "            print(sql_command)\n",
    "            con.execute(sql_command)\n",
    "        if table_name in sec_pk:\n",
    "            # Add primary key constraint\n",
    "            sql_pk = f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({sec_pk[table_name]});\"\n",
    "            print(sql_pk)\n",
    "            con.execute(sql_pk)\n",
    "\n",
    "\n",
    "        print(f\"Loaded '{file_name}' into DuckDB view '{table_name}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading '{file_name}': {e}\")\n",
    "\n",
    "# Now you can query the data in DuckDB using SQL\n",
    "# For example, to select the first few rows of one of your tables:\n",
    "# table_to_query = csv_files[0].split('.')[0] # Get the name of the first table\n",
    "# result = con.execute(f\"SELECT * FROM {table_to_query} LIMIT 5;\").fetchdf()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_duckdb_schema(conn: duckdb.DuckDBPyConnection, table_name: str):\n",
    "  \"\"\"Prints the schema of a specified table in a DuckDB database.\n",
    "\n",
    "  Args:\n",
    "    conn: An active DuckDB connection object.\n",
    "    table_name: The name of the table whose schema to print.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    schema_info = conn.execute(f\"PRAGMA table_info('{table_name}')\").fetchall()\n",
    "    if not schema_info:\n",
    "      print(f\"Table '{table_name}' not found.\")\n",
    "      return\n",
    "\n",
    "    print(f\"Schema for table: {table_name}\")\n",
    "    print(\"-\" * (16 + len(table_name)))\n",
    "    print(f\"{'Column ID':<10} {'Name':<20} {'Type':<15} {'NotNull':<8} {'PrimaryKey':<12} {'Default':<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    for column in schema_info:\n",
    "      cid, name, dtype, notnull, pk, default = column\n",
    "      print(f\"{cid:<10} {name:<20} {dtype:<15} {bool(notnull):<8} {bool(pk):<12} {str(default):<20}\")\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "  except duckdb.CatalogException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"Could not retrieve schema for table '{table_name}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:46:11.063245Z",
     "iopub.status.busy": "2025-04-12T22:46:11.063015Z",
     "iopub.status.idle": "2025-04-12T22:46:11.093073Z",
     "shell.execute_reply": "2025-04-12T22:46:11.092411Z",
     "shell.execute_reply.started": "2025-04-12T22:46:11.063227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   adsh      cik         name     sic countryba stprba  \\\n",
      "0  0001193125-24-075464  1009001  CAMECO CORP  1090.0        CA     SK   \n",
      "1  0001193125-20-088317  1009001  CAMECO CORP  1090.0        CA     SK   \n",
      "2  0001193125-21-087174  1009001  CAMECO CORP  1090.0        CA     SK   \n",
      "3  0001193125-22-081448  1009001  CAMECO CORP  1090.0        CA     SK   \n",
      "4  0001193125-23-083565  1009001  CAMECO CORP  1090.0        CA     SK   \n",
      "5  0001193125-18-099445  1009001  CAMECO CORP  1090.0        CA     SK   \n",
      "6  0001193125-19-092356  1009001  CAMECO CORP  1090.0        CA     SK   \n",
      "\n",
      "      cityba    zipba            bas1  bas2  ...            accepted prevrpt  \\\n",
      "0  SASKATOON  S7M 1J3  2121 11TH ST W  None  ... 2024-03-22 17:23:00       0   \n",
      "1  SASKATOON  S7M 1J3  2121 11TH ST W  None  ... 2020-03-27 14:02:00       0   \n",
      "2  SASKATOON  S7M 1J3  2121 11TH ST W  None  ... 2021-03-19 13:08:00       0   \n",
      "3  SASKATOON  S7M 1J3  2121 11TH ST W  None  ... 2022-03-22 14:05:00       0   \n",
      "4  SASKATOON  S7M 1J3  2121 11TH ST W  None  ... 2023-03-29 15:22:00       0   \n",
      "5  SASKATOON  S7M 1J3  2121 11TH ST W  None  ... 2018-03-28 15:57:00       0   \n",
      "6  SASKATOON  S7M 1J3  2121 11TH ST W  None  ... 2019-03-29 13:29:00       0   \n",
      "\n",
      "  detail             instance nciks aciks pubfloatusd floatdate floataxis  \\\n",
      "0      1  d764353d40f_htm.xml     1  None        None      None      None   \n",
      "1      1     ccj-20191231.xml     1  None        None      None      None   \n",
      "2      1     ccj-20201231.xml     1  None        None      None      None   \n",
      "3      1  d328590d40f_htm.xml     1  None        None      None      None   \n",
      "4      1  d381976d40f_htm.xml     1  None        None      None      None   \n",
      "5      1     ccj-20171231.xml     1  None        None      None      None   \n",
      "6      1     ccj-20181231.xml     1  None        None      None      None   \n",
      "\n",
      "   floatmems  \n",
      "0       None  \n",
      "1       None  \n",
      "2       None  \n",
      "3       None  \n",
      "4       None  \n",
      "5       None  \n",
      "6       None  \n",
      "\n",
      "[7 rows x 40 columns]\n",
      "Schema for table: sub\n",
      "-------------------\n",
      "Column ID  Name                 Type            NotNull  PrimaryKey   Default             \n",
      "-------------------------------------------------------------------------------------\n",
      "0          adsh                 VARCHAR         1        0            True                \n",
      "1          cik                  BIGINT          0        0            False               \n",
      "2          name                 VARCHAR         0        0            False               \n",
      "3          sic                  DOUBLE          0        0            False               \n",
      "4          countryba            VARCHAR         0        0            False               \n",
      "5          stprba               VARCHAR         0        0            False               \n",
      "6          cityba               VARCHAR         0        0            False               \n",
      "7          zipba                VARCHAR         0        0            False               \n",
      "8          bas1                 VARCHAR         0        0            False               \n",
      "9          bas2                 VARCHAR         0        0            False               \n",
      "10         baph                 BIGINT          0        0            False               \n",
      "11         countryma            VARCHAR         0        0            False               \n",
      "12         stprma               VARCHAR         0        0            False               \n",
      "13         cityma               VARCHAR         0        0            False               \n",
      "14         zipma                VARCHAR         0        0            False               \n",
      "15         mas1                 VARCHAR         0        0            False               \n",
      "16         mas2                 VARCHAR         0        0            False               \n",
      "17         countryinc           VARCHAR         0        0            False               \n",
      "18         stprinc              VARCHAR         0        0            False               \n",
      "19         ein                  DOUBLE          0        0            False               \n",
      "20         former               VARCHAR         0        0            False               \n",
      "21         changed              VARCHAR         0        0            False               \n",
      "22         afs                  VARCHAR         0        0            False               \n",
      "23         wksi                 BIGINT          0        0            False               \n",
      "24         fye                  DOUBLE          0        0            False               \n",
      "25         form                 VARCHAR         0        0            False               \n",
      "26         period               DOUBLE          0        0            False               \n",
      "27         fy                   DOUBLE          0        0            False               \n",
      "28         fp                   VARCHAR         0        0            False               \n",
      "29         filed                BIGINT          0        0            False               \n",
      "30         accepted             TIMESTAMP       0        0            False               \n",
      "31         prevrpt              BIGINT          0        0            False               \n",
      "32         detail               BIGINT          0        0            False               \n",
      "33         instance             VARCHAR         0        0            False               \n",
      "34         nciks                BIGINT          0        0            False               \n",
      "35         aciks                VARCHAR         0        0            False               \n",
      "36         pubfloatusd          VARCHAR         0        0            False               \n",
      "37         floatdate            VARCHAR         0        0            False               \n",
      "38         floataxis            VARCHAR         0        0            False               \n",
      "39         floatmems            VARCHAR         0        0            False               \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = con.execute(f\"SELECT * FROM sub;\")\n",
    "print(result.fetchdf())\n",
    "\n",
    "print_duckdb_schema(con, 'sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remember to close the DuckDB connection when you're finished\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7126957,
     "sourceId": 11382185,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
